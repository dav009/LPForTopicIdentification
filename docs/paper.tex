%\documentclass[4pt,a4paper]{article}
\documentclass[4pt,a4paper,twocolumn]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{algorithm}
\usepackage{textcomp}
\usepackage{fontenc}
\usepackage{tipa}
\usepackage{framed}
\usepackage{multicol}
\usepackage{color}
\usepackage{qtree}
\usepackage{graphicx}
\usepackage{amsmath}

\usepackage{cite}
\usepackage{lastpage}
\usepackage{lmodern}




\usepackage[]{hyperref}
\hypersetup{  
	colorlinks=true,
    urlcolor=cyan           % color of external links
}

\author{David Przybilla\footnote{dav.alejandro@gmail.com , davida@coli.uni-saarland.de}\\ Term Paper for Unsupervised Semisupervised
Learning Seminar\\ Saarland University}
\title{Topic Classification of short product Reviews using Label Propagation}
\begin{document}
\twocolumn[
	 \begin{@twocolumnfalse}
    \maketitle
   \begin{abstract}
      ...
    \end{abstract}
  \end{@twocolumnfalse}
  ]




\part*{Introduction}
Twitter and Tuenti are popular microblogging services in Latinamerica,
as prices of Smartphones became more accessible to people big communities
have grown around this services.\\
These communities are actively commenting everything from political events to products experiences.\\
Therefore it has become of interest for many companies to analyze the microblogging data in order to understand
what their clients want of their products, this led naturally to sentiment Analysis.\\ 
\\
One of the subtasks of Sentiment Analysis is to find the Topic or Aspect of an opinion,
for example given a set of opinions about a mobile phone, it is possible to label each comment
with the topic that it is referring to, this labels could be ``battery", ``design", ``operative system" etc.
This Subtask can be modelled as a classification problem, given a set of fixed possible topics.\\
\\
In the Scenario of text classification Semi-supervised techniques present two advantages:\\
First a semi-supervised method should allow to classify text by annotating only a small portion of data,thus reducing the labor of annotating.\\
Second the unlabeled data is used during training, this is important since the amount of unlabeled data in these tasks is abundant and available, therefore it can be used to provide extra knowledge to the model.\\
\\
In ~\cite{Ando:2005:FLP:1046920.1194905} propose a semi-supervised approach using linear classifiers for multiple learning tasks.\\
They proposed to create additional classifications tasks (Auxiliary Problems) aside from the Target Problem.\\
The underlying idea is that the auxiliary problems will help finding good predictors.\\
One of the constraints in this approach is that auxiliary problems should be  able to automatically generate labelled data from the original unlabeled data.\\
\\
In contrast ~\cite{Zhu:2005:SLG:1104523} proposes a graph approach called label propagation for
doing semi-supervised learning.\\
This approach maps the data to a graph representation, then labelled instances propagate their labels through the graph, allowing unlabelled data to adopt the label of those instances which are similar.\\
~\cite{Speriosu_twitterpolarity} uses Label Propagation for doing Polarity Classification on tweets.\\
\\
Though Classifying text has been a widely studied topic,the focus has been on long documents,
whereas tweets are at most 144 characters long.\\
The new trends in these social networks have led to research about classification in short texts, the latter has  shown that it arises new challenges, and previous approaches are not  effective.\\
One of the reasons is that  user generated comments in the mentioned services tend to be extremly short, leading to sparce feature representations.\\
\\
In respect to short text classification ~\cite{Fan:2010:NMC:1916732.1917677} proposes  to do Feature Extension to deal with data sparcity, in his approach each comment is extended with extra words from an expansion vocabulary.\\
~\cite{Gabrilovich:2006:OBB:1597348.1597395} proposes on the other hand to use encyclopedic knowledge from wikipedia for extending the short comments.\\
As opposed to the above ones  ~\cite{Sun:2012:STC:2348283.2348511} reduces the word space of the comments to keywords and use information retrieval with a voting scheme to find labels for short comments.\\
\\
This paper describes the setup of an experiment for classifying short-text comments of product reviews extracted from twitter.\\
Two semi-supervised techniques are used, Label Propagation ~\cite{Zhu:2005:SLG:1104523}  and  a variation of Structural learning problem for multitasks ~\cite{Ando:2005:FLP:1046920.1194905}.\\
The next sections describe briefly each of the proposed methods and how they were adapted to the task, then the pre-processing involved. \\
Addionally the results are shown, where both methods are compared among themselves and to a supervised approach.
Finally a short conclusion and future work are discussed.\\
\\
The source code of the implementation is available at github\footnote{\url{https://github.com/dav009/LPForTopicIdentification}},the datasets however are not public, since they are constrained by a permission license.

\part*{Datasets}
The Datasets of this experiments were provided by Meridean.\\
Meridean\footnote{\url{http://http://merideangroup.com/}} is a Colombian company which extracts tweets
mentioning latinamerican companies or products.\\
\\
The datasets are separated by product.\\
There are 3 datasets in this experiment:
\begin{itemize}
	\item Clothing-Brand dataset
	\item Mobile-Phone dataset
	\item hygienic-product dataset
\end{itemize}

Each dataset is composed of tuples,each tuple contains : the source of the opinion, the opinion, the polarity and the topic.\\

\begin{table}[h]
\centering
\begin{tabular}{| l |}
\hline
\textbf{Message:}\\
$\#$ProbandoXperiaArcS Gracias @TalkMex.\\
Las fotos se ven tan nitidas.\\
\hline
\textbf{Translation:}\\
$\#$TestingXperiaArcs Thanks to @TalkMex.\\
Pictures are very sharp.\\
\hline
\textbf{Topic:}\\
Camera\\
\hline
\end{tabular}
\caption{Sample Tuple}
\label{tab:sampleTuple}
\end{table}


\part*{Pre-processing}

The Datasets used in this experiment are actual data crawled from twitter and other sources, therefore there is a lot of noise in them.\\
Some of the problems are (but not limited) to:\\
\begin{itemize}
	\item Miss spelled words, from typo errors to lack of accents.
	\item Internet Language, replacing some letters for others whose phonetics are similar i.e: ``\textbf{qu}iero" (I want) for ``\textbf{k}iero", abbreviations and expressions (``Jaja'' ``jiji" ... )
	\item Twitter Jargon such as: ``RT:",``@"..
\end{itemize} 

The pre-processing done was the following:
\begin{enumerate}
	\item Remove Strange characters, such as hearts, and other unicode characters
	\item Remove some of the Twitter Jargon 
	\item Use \href{http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/}{TreeTagger} ~\cite{Schmid94probabilisticpart-of-speech} for getting the part of speech and the stem of each word in each comment
	\item discard those words that are not adjectives, nouns or verbs
	\item replace each word by its stem in lowercase
	\item remove accents from words
\end{enumerate}

When it comes to pre-processing there could be wide number of possible 
tasks that can be done, I try to keep it simple given the time constraints. \\
\\
As a result of this pre-processing each comment is converted into a bag of keywords.\\
This will be later transform into a vector space representation.


%% for future work mention that words like 'camera' that turn out to be good predictor, can be biased by the fact that is misswritten 'camera '  'cmarea'

\part*{Label Propagation}

This Semi-supervised learning graph method was proposed by Zhu ~\cite{Zhu:2005:SLG:1104523}.\\
The idea behind Label propagation is similar to K-Neighbors, nevertheless Label propagation make use of the unlabeled data during the training process.\\

This approach maps the data to a graph representation.
In this representation each Arc of the graph will connect two nodes only if the two nodes are similar,
and the weights of the arcs are directly proportional to the similarity of the incident nodes.\\

With respect to our classification task,each node in the graph corresponds to the feature vector of a comment.
The weights of the arcs are given by the cosine distance among the vectors.\\
The final representation is a complete graph.\\
\\
In the LP algorithm, the label information of any
vertex in a graph is propagated to nearby vertices
through weighted edges until a global stable stage is
achieved.~\cite{Chen:2006:REU:1220175.1220192}.
If a weight arc is high, the label will travel easier.\\
\\


 

\part*{Structure Learning}
A Semi-supervised learning method proposed in ~\cite{Ando:2005:FLP:1046920.1194905}.\\

\part*{Feature Generation}

\part*{Experiment}


La

\part*{Results}

\part*{Future Work}

\bibliography{paper}{}
\bibliographystyle{alpha}



\end{document}


